import express from "express";
import cors from "cors";
import fetch from "node-fetch";
import { readFileSync } from "fs";
import { fileURLToPath } from "url";
import { dirname, join } from "path";
import { detectIntent } from "./aiRouter.js";
import 'dotenv/config';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const app = express();
app.use(cors());
app.use(express.json());

const GROQ_API_KEY = process.env.GROQ_API_KEY;

// Charger les offres d'emploi
const jobsData = JSON.parse(
  readFileSync(join(__dirname, 'data', 'jobs.json'), 'utf-8')
);

// Route pour rÃ©cupÃ©rer toutes les offres
app.get("/jobs", (req, res) => {
  res.json({ jobs: jobsData });
});

// Route pour rÃ©cupÃ©rer une offre spÃ©cifique
app.get("/jobs/:id", (req, res) => {
  const job = jobsData.find(j => j.id === req.params.id);
  if (job) {
    res.json({ job });
  } else {
    res.status(404).json({ error: "Offre non trouvÃ©e" });
  }
});

// Route pour rechercher des offres
app.post("/jobs/search", (req, res) => {
  const { skills, location, type } = req.body;
  
  let filtered = jobsData;
  
  // Filtrer par compÃ©tences
  if (skills && skills.length > 0) {
    filtered = filtered.filter(job => 
      skills.some(skill => 
        job.skills_required.some(s => 
          s.toLowerCase().includes(skill.toLowerCase())
        )
      )
    );
  }
  
  // Filtrer par localisation
  if (location) {
    filtered = filtered.filter(job => 
      job.location.toLowerCase().includes(location.toLowerCase())
    );
  }
  
  // Filtrer par type (Alternance/Stage)
  if (type) {
    filtered = filtered.filter(job => 
      job.type.toLowerCase() === type.toLowerCase()
    );
  }
  
  res.json({ jobs: filtered, count: filtered.length });
});

// Route pour le matching intelligent avec l'IA
app.post("/jobs/match", async (req, res) => {
  const { userProfile, topN = 3 } = req.body;
  
  if (!GROQ_API_KEY) {
    return res.json({ error: "Configuration API manquante" });
  }
  
  try {
    // CrÃ©er un prompt pour l'IA avec le profil utilisateur et les offres
    const prompt = `
Tu es un expert en matching emploi/candidat. 
Voici le profil de l'utilisateur :
${JSON.stringify(userProfile, null, 2)}

Voici les offres d'emploi disponibles :
${JSON.stringify(jobsData.slice(0, 10), null, 2)}

Analyse et retourne UNIQUEMENT un JSON (sans markdown) avec les ${topN} meilleures offres pour ce profil.
Format attendu :
{
  "matches": [
    {
      "job_id": "job_xxx",
      "score": 85,
      "reasons": ["Raison 1", "Raison 2"],
      "concerns": ["Point d'attention 1"]
    }
  ]
}
`;

    const response = await fetch(
      "https://api.groq.com/openai/v1/chat/completions",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${GROQ_API_KEY}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "llama-3.3-70b-versatile",
          messages: [{ role: "user", content: prompt }],
          max_tokens: 1000,
          temperature: 0.3,
        }),
      }
    );

    const data = await response.json();
    const aiResponse = data.choices?.[0]?.message?.content;
    
    // Parser la rÃ©ponse JSON de l'IA
    const cleanResponse = aiResponse.replace(/```json|```/g, "").trim();
    const matchResults = JSON.parse(cleanResponse);
    
    // Enrichir avec les dÃ©tails complets des offres
    const enrichedMatches = matchResults.matches.map(match => ({
      ...match,
      job: jobsData.find(j => j.id === match.job_id)
    }));
    
    res.json({ matches: enrichedMatches });
    
  } catch (err) {
    console.error("Erreur matching:", err);
    res.json({ error: "Erreur lors du matching" });
  }
});

app.post("/chat-smart", async (req, res) => {
  const { conversation = [], message, userProfile } = req.body;

  if (!GROQ_API_KEY) {
    return res.json({ error: "API KEY manquante" });
  }

  // 1ï¸âƒ£ DÃ©tection de l'intention
  const intentData = await detectIntent(conversation, message, GROQ_API_KEY);
  console.log("ðŸ§  INTENT:", intentData);

  let responseData = {};

  // 2ï¸âƒ£ ExÃ©cuter l'action selon l'intention
  switch (intentData.intent) {
    case "show_all_jobs":
      responseData = { jobs: jobsData };
      break;

    case "search_jobs":
      const { skills, location, type } = intentData.filters;
      let filtered = jobsData;

      if (skills?.length)
        filtered = filtered.filter(job =>
          skills.some(skill =>
            job.skills_required.some(s => s.toLowerCase().includes(skill.toLowerCase()))
          )
        );

      if (location)
        filtered = filtered.filter(job =>
          job.location.toLowerCase().includes(location.toLowerCase())
        );

      if (type)
        filtered = filtered.filter(job =>
          job.type.toLowerCase() === type.toLowerCase()
        );

      responseData = { jobs: filtered };
      break;

    case "job_recommendation":
      // Appel Ã  /jobs/match (on peut le faire en interne)
      const matchPrompt = `
Tu es un expert en matching emploi/candidat.
Profil utilisateur: ${JSON.stringify(userProfile, null, 2)}

Offres disponibles: ${JSON.stringify(jobsData.slice(0, 10), null, 2)}

Retourne UNIQUEMENT un JSON (sans markdown) avec les 3 meilleures offres pour ce profil.
Format: {
  "matches": [
    { "job_id": "job_xxx", "score": 85, "reasons": ["..."], "concerns": ["..."] }
  ]
}`;

      const matchResponse = await fetch("https://api.groq.com/openai/v1/chat/completions", {
        method: "POST",
        headers: {
          Authorization: `Bearer ${GROQ_API_KEY}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "llama-3.3-70b-versatile",
          messages: [{ role: "user", content: matchPrompt }],
          max_tokens: 1000,
          temperature: 0.3,
        }),
      });

      const matchData = await matchResponse.json();
      const matchResult = matchData.choices?.[0]?.message?.content.replace(/```json|```/g, "").trim();
      const matches = JSON.parse(matchResult);
      
      responseData = { 
        matches: matches.matches.map(m => ({
          ...m,
          job: jobsData.find(j => j.id === m.job_id)
        }))
      };
      break;

    case "job_details":
      let targetJob = null;
      
      if (intentData.filters.position_in_list > 0) {
        const index = intentData.filters.position_in_list - 1;
        targetJob = jobsData[index];
      } else if (intentData.filters.job_id) {
        targetJob = jobsData.find(j => j.id === intentData.filters.job_id);
      }
      
      if (targetJob) {
        responseData = { job: targetJob };
      } else {
        responseData = { answer: "Je n'ai pas trouvÃ© cette offre." };
      }
      break;

    default:
      responseData = { answer: "Je peux te montrer des offres, recommander ou filtrer ðŸ˜Š" };
  }

  // 3ï¸âƒ£ ðŸ”¥ NOUVELLE PARTIE : GÃ©nÃ©ration d'une rÃ©ponse naturelle avec l'IA
  const naturalResponse = await generateNaturalResponse(
    intentData.intent,
    responseData,
    message,
    conversation,
    userProfile,
    GROQ_API_KEY
  );

  res.json(naturalResponse);
});

// ðŸ”¥ Nouvelle fonction pour gÃ©nÃ©rer des rÃ©ponses naturelles
async function generateNaturalResponse(intent, data, userMessage, conversation, userProfile, apiKey) {
  
  // Si c'est des jobs, on laisse le front gÃ©rer l'affichage
  if (data.jobs || data.matches || data.job) {
    return data;
  }

  // Pour les rÃ©ponses textuelles, on enrichit avec l'IA
  const contextPrompt = `
Tu es LinkPick, un assistant de recherche d'emploi sympathique et efficace.

Contexte de la conversation:
${conversation.slice(-3).map(m => `${m.role}: ${m.content}`).join('\n')}

Message utilisateur actuel: "${userMessage}"

Intention dÃ©tectÃ©e: ${intent}

Profil utilisateur connu:
${JSON.stringify(userProfile, null, 2)}

**TON RÃ”LE:**
RÃ©ponds de maniÃ¨re naturelle, amicale et personnalisÃ©e. 
- Utilise des emojis avec modÃ©ration 
- Sois concis mais utile
- Propose toujours une action concrÃ¨te
- Adapte ton ton au contexte (encourageant, informatif, etc.)

GÃ©nÃ¨re une rÃ©ponse courte (2-3 phrases max).
`;

  const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${apiKey}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "llama-3.3-70b-versatile",
      messages: [{ role: "user", content: contextPrompt }],
      max_tokens: 200,
      temperature: 0.7,
    }),
  });

  const aiData = await response.json();
  const answer = aiData.choices?.[0]?.message?.content || "Je suis lÃ  pour t'aider !";

  return { answer };
}

// Route chat existante
app.post("/chat", async (req, res) => {
  const { prompt } = req.body;

  if (!GROQ_API_KEY) {
    console.error("âŒ GROQ_API_KEY non dÃ©finie");
    return res.json({ answer: "Configuration API manquante" });
  }

  try {
    const response = await fetch(
      "https://api.groq.com/openai/v1/chat/completions",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${GROQ_API_KEY}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          model: "llama-3.3-70b-versatile",
          messages: [{ role: "user", content: prompt }],
          max_tokens: 200,
          temperature: 0.7,
        }),
      }
    );

    const data = await response.json();
    console.log("Status:", response.status);
    console.log("RÃ©ponse:", data);

  const updatedProfile = await extractUserProfile(
    [...conversation, { role: 'user', content: message }],
    GROQ_API_KEY
  );

  naturalResponse.updatedProfile = updatedProfile;

    if (!response.ok) {
      console.error("âŒ Erreur:", data);
      return res.json({ answer: "Erreur du modÃ¨le." });
    }

    const answer = data.choices?.[0]?.message?.content ?? "Pas de rÃ©ponse";
    console.log("âœ… RÃ©ponse gÃ©nÃ©rÃ©e:", answer);
    res.json({ answer });
  } catch (err) {
    console.error("âŒ Erreur backend:", err.message);
    res.json({ answer: "Le bot est indisponible." });
  }
});

// Ajoute cette fonction
async function extractUserProfile(conversation, apiKey) {
  const prompt = `
Analyse cette conversation et extrait le profil de l'utilisateur.

Conversation:
${conversation.map(m => `${m.role}: ${m.content}`).join('\n')}

Retourne UNIQUEMENT ce JSON (sans markdown):
{
  "skills": ["compÃ©tence1", "compÃ©tence2"],
  "location": "ville si mentionnÃ©e",
  "education": "niveau si mentionnÃ©",
  "preferences": "prÃ©fÃ©rences type d'entreprise/poste",
  "experience": "annÃ©es si mentionnÃ©"
}
`;

  const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${apiKey}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: "llama-3.3-70b-versatile",
      messages: [{ role: "user", content: prompt }],
      max_tokens: 300,
      temperature: 0.2,
    }),
  });

  const data = await response.json();
  const result = data.choices?.[0]?.message?.content.replace(/```json|```/g, "").trim();
  return JSON.parse(result);
}

app.listen(3000, () => {
  console.log("ðŸš€ Server running on http://localhost:3000");
  console.log("GROQ_API_KEY prÃ©sente:", !!GROQ_API_KEY);
  console.log(`ðŸ“Š ${jobsData.length} offres d'emploi chargÃ©es`);
});
