// aiRouter.js
export async function detectIntent(conversation, message, apiKey) {
    // RÃ©cupÃ©rer le dernier message bot avec des offres
    const lastBotMessage = conversation
      .slice()
      .reverse()
      .find(msg => msg.role === 'bot' && msg.content.includes('offres'));
    
    const prompt = `
  Analyse ce message utilisateur dans le contexte d'un chatbot de recherche d'emploi.
  
  Historique rÃ©cent:
  ${conversation.slice(-4).map(m => `${m.role}: ${m.content}`).join('\n')}
  
  Message actuel: "${message}"
  
  **RÃˆGLES DE DÃ‰TECTION:**
  
  1. Si l'utilisateur demande "plus de dÃ©tails", "dÃ©tails sur", "parle-moi de", "la premiÃ¨re", "le 2", "l'offre 3" :
     â†’ intent = "job_details"
     â†’ Extrais le numÃ©ro (1, 2, 3...) et mets-le dans position_in_list
     
  2. Si l'utilisateur dit "toutes les offres", "montre-moi tout" :
     â†’ intent = "show_all_jobs"
  
  3. Si l'utilisateur cherche avec des filtres (compÃ©tences, ville, type) :
     â†’ intent = "search_jobs"
     â†’ Extrais : skills (tableau), location (string), type (Alternance/Stage)
  
  4. Si l'utilisateur demande des recommandations basÃ©es sur son profil :
     â†’ intent = "job_recommendation"
  
  5. Sinon â†’ intent = "general_chat"
  
  **EXEMPLES:**
  - "Plus de dÃ©tails sur la premiÃ¨re" â†’ position_in_list: 1
  - "Parle-moi de l'offre 2" â†’ position_in_list: 2
  - "La 3Ã¨me offre m'intÃ©resse" â†’ position_in_list: 3
  
  Retourne UNIQUEMENT ce JSON (sans markdown ni texte):
  {
    "intent": "search_jobs | show_all_jobs | job_recommendation | job_details | general_chat",
    "filters": {
      "skills": [],
      "location": "",
      "type": "",
      "job_id": "",
      "position_in_list": 0
    }
  }
  `;
  
    const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${apiKey}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "llama-3.3-70b-versatile",
        messages: [{ role: "user", content: prompt }],
        max_tokens: 300,
        temperature: 0.1, // ðŸ‘ˆ Baisse la tempÃ©rature pour plus de prÃ©cision
      }),
    });
  
    const data = await response.json();
    const aiResponse = data.choices?.[0]?.message?.content || "{}";
    
    const cleaned = aiResponse.replace(/```json|```/g, "").trim();
    return JSON.parse(cleaned);
  }